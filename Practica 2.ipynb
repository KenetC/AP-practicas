{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZSWq2lIEnbB"
   },
   "source": [
    "# Práctica 2: Introducción a PyTorch\n",
    "\n",
    "## a) Calculando el gradiente mediante Autograd\n",
    "\n",
    "En primer lugar, vamos a calcular del gradiente para el perceptrón simple con función de activación sigmoidea que vimos en la teoría. Pero esta vez, en lugar de realizar manualmente el proceso de backpropagation, vamos a usar el módulo `autograd` de PyTorch.\n",
    "\n",
    "La función $f(x, w)$ a la cual queremos encontrarle el gradiente es:\n",
    "\n",
    "> $f(\\mathbf{x}, \\mathbf{w}) = \\frac{1}{1 + e^{2-(w_0 x_0 + w_1 x_1 + w_2)}}$\n",
    "\n",
    "Definimos entonces la función utilizando `torch.tensor` (recordar usar el parámetro `requires_grad = True` para que PyTorch guarde los gradientes) y realizamos la pasada \"forward\" para los siguientes valores de x y w:\n",
    "\n",
    "> $\\mathbf{x} = (-1, -2)$\n",
    "\n",
    "> $\\mathbf{w} = (2, -3, -3)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UczyYh5Nj2u5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu funciona!!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"gpu funciona!!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "x = torch.tensor([-1.0,-2.0],device=device,requires_grad = True)\n",
    "w = torch.tensor([2.0,-3.0,-3.0],device=device,requires_grad = True)\n",
    "\n",
    "def f(x,w):\n",
    "    x0,x1 = x \n",
    "    w0,w1,w2 = w \n",
    "    z = 2-(w0*x0+w1*x1+w2)\n",
    "    return 1/(1 + torch.exp(z))\n",
    "y = f(x,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkrbxHMukzHQ"
   },
   "source": [
    "Ahora, utilizando la función `f.backward()` computamos los gradientes $\\frac{\\partial f}{ \\partial \\mathbf{x}}$ y $\\frac{\\partial f}{ \\partial \\mathbf{w}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q477bpjr77xp"
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hXewlL_8YHMU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradiente df/dx = tensor([ 0.3932, -0.5898], device='cuda:0')\n",
      "Gradiente df/dw = tensor([-0.1966, -0.3932,  0.1966], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradiente df/dx = \" + str(x.grad))\n",
    "print(\"Gradiente df/dw = \" + str(w.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsXTQ9wJnK2j"
   },
   "source": [
    "## b) Minimizando una función con Gradient Descent\n",
    "\n",
    "Ahora, vamos a implementar usar el algorítmo de gradiente descendiente (utilizando Autograd para computar el gradiente) para minimizar la función cuadrática $$f(x) = 2x^2 + x + 4$$\n",
    "\n",
    "Utilizaremos la implementación `torch.optim.SGD` de gradiente descendiente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.SGD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AKc75VsMYS4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([1.], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.9500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.9020], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.8559], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.8117], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.7692], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.7284], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.6893], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.6517], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.6157], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.5810], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.5478], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.5159], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.4853], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.4558], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.4276], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.4005], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.3745], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.3495], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.3255], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.3025], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.2804], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.2592], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.2388], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.2193], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.2005], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.1825], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.1652], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.1486], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.1326], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.1173], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.1026], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.0885], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.0750], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.0620], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.0495], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.0375], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.0260], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.0150], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([0.0044], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0058], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0156], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0249], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0339], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0426], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0509], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0588], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0665], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0738], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0809], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0876], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.0941], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1004], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1064], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1121], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1176], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1229], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1280], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1329], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1376], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1421], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1464], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1505], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1545], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1583], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1620], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1655], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1689], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1721], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1752], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1782], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1811], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1839], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1865], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1890], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1915], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1938], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1961], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.1982], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2003], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2023], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2042], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2060], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2078], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2095], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2111], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2127], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2141], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2156], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2170], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2183], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2195], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2208], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2219], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2231], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2241], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2252], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2262], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2271], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2280], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2289], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2298], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2306], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2313], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2321], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2328], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2335], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2342], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2348], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2354], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2360], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2365], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2371], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2376], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2381], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2386], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2390], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2395], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2399], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2403], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2407], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2411], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2414], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2418], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2421], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2424], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2427], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2430], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2433], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2435], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2438], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2441], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2443], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2445], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2447], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2449], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2451], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2453], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2455], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2457], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2459], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2460], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2462], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2464], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2465], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2466], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2468], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2469], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2470], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2471], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2473], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2474], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2475], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2476], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2477], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2478], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2479], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2479], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2480], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2481], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2482], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2483], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2483], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2484], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2485], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2485], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2486], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2486], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2487], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2487], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2488], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2488], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2489], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2489], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2490], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2490], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2491], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2491], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2491], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2492], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2492], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2492], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2493], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2493], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2493], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2493], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2494], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2494], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2494], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2494], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2495], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2495], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2495], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2495], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2495], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2496], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2496], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2496], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2496], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2496], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2496], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2497], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2497], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2497], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2497], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2497], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2497], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2497], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2497], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2498], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2499], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n",
      "X = tensor([-0.2500], requires_grad=True), g(x) = <function g at 0x7228434fe290>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7228433b03d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definimos la funcion a minimizar \n",
    "def g(x): \n",
    "    return 2*x**2 + x +4\n",
    "\n",
    "# Definir la variable que será el parámetro a optimizar\n",
    "x = torch.tensor([1.0],requires_grad=True)\n",
    "\n",
    "# Definir el optimizador, indicando el parámetro a optimizar y el learning rate\n",
    "optimizer = torch.optim.SGD(params=[x],lr=1e-2)\n",
    "\n",
    "# Acumuladores que usaremos para guardar los valores sucesivos de x, y\n",
    "g_values = []\n",
    "x_values = []\n",
    "\n",
    "# Loop de optimización\n",
    "for i in range(1000):\n",
    "\n",
    "    # Setemos en 0 los gradientes de todos los elementos\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Pasada forward: ejecutar la función a minimizar\n",
    "    y = g(x)\n",
    "\n",
    "    print(\"X = \" + str(x) + \", g(x) = \" + str(g))\n",
    "\n",
    "    # Pasada backward: computar los gradientes\n",
    "    y.backward()\n",
    "\n",
    "    # Actualizar los pesos dando un paso de gradiente descendiente\n",
    "    optimizer.step()\n",
    "\n",
    "    # Guardar los valores para luego plotearlos\n",
    "    g_values.append(y.data.item())\n",
    "    x_values.append(x.data.item())\n",
    "\n",
    "# Ploteo los valores\n",
    "plt.title(\"Optimizando la función g = 2 * x**2 + x + 4\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.plot(x_values,g_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTAAwWN2DWEH"
   },
   "source": [
    "# c) Implementando un MLP en PyTorch para predicción del procentaje de grasa corporal\n",
    "\n",
    "Contamos con una base de datos [1] de 252 mediciones del porcentaje de grasa corporal de 252 personas diferentes, el cual puede ser estimado mediante otras características, como la edad, el peso, y mediciones en diferentes partes del cuerpo. A partir de estos datos se pretende desarrollar un sistema que permita predecir dicho porcentaje a partir de las características.\n",
    "\n",
    "[1]: Olson, R.S., La Cava, W., Orzechowski, P. et al. PMLB: a large benchmark suite for machine learning evaluation and comparison. BioData Mining 10, 36 (2017). https://epistasislab.github.io/pmlb/profile/560_bodyfat.html\n",
    "\n",
    "Antes de comenzar, vamos a instalar el paquete de Python que contiene la base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GzDa1RLL3TUF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pmlb\n",
      "  Downloading pmlb-1.0.1.post3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from pmlb) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.24.0 in /usr/lib/python3/dist-packages (from pmlb) (2.25.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /usr/lib/python3/dist-packages (from pmlb) (1.3.5)\n",
      "Installing collected packages: pmlb\n",
      "Successfully installed pmlb-1.0.1.post3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pmlb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZoNrd9SEFQ9"
   },
   "source": [
    "Ahora vamos a generar un histograma de todas las mediciones del porcentaje con todos los datos disponibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-D-sOjKKSdmp",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fila de ejemplo:\n",
      "['Density', 'Age', 'Weight', 'Height', 'Neck', 'Chest', 'Abdomen', 'Hip', 'Thigh', 'Knee', 'Ankle', 'Biceps', 'Forearm', 'Wrist', 'target']\n",
      "[  1.0708  23.     154.25    67.75    36.2     93.1     85.2     94.5\n",
      "  59.      37.3     21.9     32.      27.4     17.1   ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pmlb import fetch_data\n",
    "seed = 42 \n",
    "# Importamos el dataset\n",
    "body_fat = fetch_data('560_bodyfat')\n",
    "body_fat.describe()\n",
    "\n",
    "# Extraigo los datos (features) y los porcentajes (etiquetas a predecir)\n",
    "data = body_fat.loc[:, body_fat.columns != 'target'].to_numpy()\n",
    "percentages = body_fat.loc[:, body_fat.columns == 'target'].to_numpy()\n",
    "\n",
    "data = data.astype(np.float32)\n",
    "percentages = percentages.astype(np.float32)\n",
    "\n",
    "print(\"Fila de ejemplo:\")\n",
    "print(list(body_fat.columns))\n",
    "print(data[0,:])\n",
    "\n",
    "# Dibujo un histograma del porcentaje de grasa corporal usando todos los datos\n",
    "_ = plt.hist( percentages , 50, density=True, facecolor='g', alpha=0.75)\n",
    "_ = plt.title(\"Porcentaje de grasa corporal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgc2qJKLmhsB"
   },
   "source": [
    "Particionamos los datos en entrenamiento y prueba usando la función `sklearn.model_selection.train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5WWTSCnnVyRK"
   },
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split\n",
    "\n",
    " # Particiono los datos en entrenamiento y prueba usando el método de scikitlearn\n",
    " X_train, X_test, y_train, y_test = train_test_split(data,percentages,test_size=0.33,random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_D3sJMCoB_K"
   },
   "source": [
    "Ahora implementaremos en PyTorch un Perceptrón multicapa que usaremos como regresor del porcentaje de grasa corporal (ejemplo basado en el curso de [RPI](https://rpi.analyticsdojo.com/)).\n",
    "\n",
    "El perceptrón deberá contar con 3 capas:\n",
    "- Las dos primeras con 200 neuronas, y deberán usar la función de activación ReLU.\n",
    "- La última con una única neurona cuya salida sea un valor escalar que corresponda al porcentaje de grasa corporal estimado de la persona, que no deberá utilizar ninguna función de activación.\n",
    "\n",
    "Algunas clases de PyTorch que resultarán útiles para implementar el modelo, son:\n",
    "- `torch.nn.Linear`: Implementa una capa totalmente conectada. Es necesario especificarle el número de parámetros de entrada y de salida.\n",
    "- `torch.nn.functional.relu`: Implementa la función de activación ReLU.\n",
    "\n",
    "Además, utilizaremos el optimizador `torch.optim.Adam` y la función de pérdida `torch.nn.MSELoss` (error cuadrático medio).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91rAzYsjkAUa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Tamaño del batch de entrenamiento\n",
    "batch_size = 32\n",
    "\n",
    "# Tasa de aprendizaje inicial para el gradiente descendente\n",
    "learning_rate = 1e-3\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_features, size_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = ...\n",
    "        self.hidden2 = ...\n",
    "        self.out = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = ...\n",
    "        return x\n",
    "\n",
    "# Definimos el modelo del perceptrón\n",
    "net = Net( ... , ... , ... )\n",
    "\n",
    "# Construimos el optimizador, y le indicamos que los parámetros a optimizar\n",
    "# son los del modelo definido: net.parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam( ... , lr=learning_rate)\n",
    "\n",
    "# Definimos también la función de pérdida a utilizar\n",
    "criterion = ...\n",
    "\n",
    "# Creamos el objeto dataset que empaqueta los array de numpy para que puedan\n",
    "# ser leidos por PyTorch\n",
    "dataset = TensorDataset(torch.from_numpy(X_train).clone(), torch.from_numpy(y_train).clone())\n",
    "\n",
    "# Creamos un loader iterable indicandole que debe leer los datos a partir de\n",
    "# del dataset creado en el paso anterior. Este objeto puede ser iterado\n",
    "# y nos devuelve de a un batch (x, y).\n",
    "loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Número de épocas\n",
    "num_epochs = 5000\n",
    "\n",
    "# Lista en la que iremos guardando el valor de la función de pérdida en cada\n",
    "# etapa de entrenamiento\n",
    "loss_list = []\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for x, y in loader:\n",
    "        # Seteo en cero los gradientes de los parámetros a optimizar\n",
    "        optimizer...\n",
    "\n",
    "        # Realizo la pasada forward por la red\n",
    "        loss = ...\n",
    "\n",
    "        # Realizo la pasada backward por la red\n",
    "        loss....\n",
    "\n",
    "        # Actualizo los pesos de la red con el optimizador\n",
    "        optimizer....\n",
    "\n",
    "        # Me guardo el valor actual de la función de pérdida para luego graficarlo\n",
    "        loss_list.append(loss.data.item())\n",
    "\n",
    "        # Acumulo la loss del minibatch\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "\n",
    "    # Normalizo la loss total\n",
    "    total_loss/= len(loader.dataset)\n",
    "\n",
    "    # Muestro el valor de la función de pérdida cada 100 iteraciones\n",
    "    if i > 0 and i % 100 == 0:\n",
    "        print('Epoch %d, loss = %g' % (i, total_loss))\n",
    "\n",
    "# Muestro la lista que contiene los valores de la función de pérdida\n",
    "# y una versión suavizada (rojo) para observar la tendencia\n",
    "plt.figure()\n",
    "loss_np_array = np.array(loss_list)\n",
    "plt.plot(loss_np_array, alpha = 0.3)\n",
    "N = 60\n",
    "running_avg_loss = np.convolve(loss_np_array, np.ones((N,))/N, mode='valid')\n",
    "plt.plot(running_avg_loss, color='red')\n",
    "plt.title(\"Función de pérdida durante el entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhL0-b9J6eoD"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Definimos un método para mostrar las predicciones como un scatter plot\n",
    "# y graficamos la recta de regresión para esos datos.\n",
    "def plotScatter(x_data, y_data, title, fit_line=True):\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(x_data, y_data, '+')\n",
    "  plt.xlabel('Valor real')\n",
    "  plt.ylabel('Predicción')\n",
    "  plt.title(title)\n",
    "\n",
    "  if fit_line:\n",
    "    X, Y = x_data.reshape(-1,1), y_data.reshape(-1,1)\n",
    "    plt.plot( X, LinearRegression().fit(X, Y).predict(X) )\n",
    "\n",
    "# Dibujamos el ground truth vs las predicciones en los datos de entrenamiento\n",
    "py = net(torch.FloatTensor(X_train))\n",
    "y_pred_train = py.cpu().detach().numpy()\n",
    "plotScatter(y_train, y_pred_train, \"Training data\")\n",
    "\n",
    "# Dibujamos el ground truth vs las predicciones en los datos de test\n",
    "py = net(torch.FloatTensor(X_test))\n",
    "y_pred_test = py.cpu().detach().numpy()\n",
    "plotScatter(y_test, y_pred_test, \"Test data\")\n",
    "\n",
    "print (\"MSE medio en training: \" + str(((y_train - y_pred_train)**2).mean()))\n",
    "print (\"MSE medio en test: \" + str(((y_test - y_pred_test)**2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc8fFGSm-D99"
   },
   "source": [
    "# Entregable\n",
    "1. Encontrar el mínimo de la función *f* definida en el apartado b). Para ello, deberán encontrar primero la derivada *f'(x)* de forma analítica, y utilizarla para computar el mínimo de la función. Posteriormente, deberán corrobarar que el valor coincida con el que obtuvieron optimizando la función con gradiente descendiente.\n",
    "\n",
    "2. Compara el rendimiento de 3 perceptrones multicapa que varíen en la cantidad de neuronas en sus capas intermedia. Probar colocando 2, 10 y 200 neuronas en dichas capas, al entrenar los perceptrones durante 5000 épocas. Mostrar los resultados utilizando:\n",
    "\n",
    "* los gráficos de dispersión con la recta de regresión\n",
    "* el error medio en los datos de entrenamiento y test\n",
    "\n",
    "  Analizar la relación entre dichos resultados y la cantidad de neuronas que posee el perceptrón.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMOqHl01-Frs"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vZQ9moPMTSH"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1yJct12sdK2VlLPFF2WvTm2oK7AYYVpUG",
     "timestamp": 1632439944726
    },
    {
     "file_id": "1RNn3GVL3O9vKa_Euf2_IY95-m7Gi58mQ",
     "timestamp": 1631887093058
    },
    {
     "file_id": "1DTScby_a3yx36WxhyhZRKcVQAgx1iVdF",
     "timestamp": 1631210373349
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
